{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP48Olm8ntZSWw8Cw+2bQvw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vridhi-Wadhawan/bank-marketing-mlops/blob/main/ML_Ops_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose\n",
        "Inference logic and API integration for serving predictions."
      ],
      "metadata": {
        "id": "eSla4It67rHQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nc975NT75SO9"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import joblib\n",
        "import numpy as np # Added for numerical operations\n",
        "import datetime # Added for date/time operations if needed for week_segment/season\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# --- Load your model and pipeline ---\n",
        "# Ensure these files are copied into your Docker image (via Dockerfile)\n",
        "# and the paths are correct relative to where app.py runs inside the container.\n",
        "try:\n",
        "    with open(\"bank_marketing_k-nearest_neighbors.pkl\", \"rb\") as model_file:\n",
        "        model = pickle.load(model_file)\n",
        "    pipeline = joblib.load(\"bank_marketing_prep_pipeline.joblib\")\n",
        "    print(\"Model and pipeline loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model or pipeline: {e}\")\n",
        "    model = None\n",
        "    pipeline = None\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return \"Bank Marketing Prediction REST API is running.\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    if not model or not pipeline:\n",
        "        return jsonify({\"error\": \"Server initialization error: Model or pipeline not loaded.\"}), 500\n",
        "\n",
        "    data = request.get_json()\n",
        "\n",
        "    if not data:\n",
        "        return jsonify({\"error\": \"No input data provided\"}), 400\n",
        "\n",
        "    # Convert input JSON into DataFrame\n",
        "    # Ensure it's a list containing the dictionary if you're expecting a single prediction\n",
        "    df = pd.DataFrame([data])\n",
        "\n",
        "    # --- FEATURE ENGINEERING (Replicate from your ml_ops.py) ---\n",
        "    # This is the crucial part you need to fill in accurately.\n",
        "    # The examples below are educated guesses based on feature names.\n",
        "    # Replace these with your actual logic from ml_ops.py.\n",
        "\n",
        "    # Example: is_risk_group (based on age and default)\n",
        "    # Assuming 'default' is 'yes' or 'no'\n",
        "    df['is_risk_group'] = ((df['age'] < 25) | (df['default'] == 'yes')).astype(int)\n",
        "\n",
        "    # Example: economic_pressure_index (based on emp.var.rate and cons.price.idx)\n",
        "    df['economic_pressure_index'] = df['emp.var.rate'] * df['cons.price.idx']\n",
        "\n",
        "    # Example: week_segment and season_category (based on month and day_of_week)\n",
        "    # This requires more complex logic to map month/day_of_week to segments/seasons.\n",
        "    # You will need to bring in your exact mapping/logic from ml_ops.py.\n",
        "    # For now, let's use dummy values or basic derivation if not precisely known.\n",
        "    # You might have a specific mapping (e.g., 'may' -> Q2, 'mon' -> weekday segment)\n",
        "    month_map = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6,\n",
        "                 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\n",
        "    df['month_numeric'] = df['month'].map(month_map)\n",
        "\n",
        "    def get_week_segment(day_of_week):\n",
        "        # Example: Simple classification. Replace with your actual logic.\n",
        "        if day_of_week in ['mon', 'tue', 'wed', 'thu', 'fri']:\n",
        "            return 'weekday'\n",
        "        else:\n",
        "            return 'weekend'\n",
        "    df['week_segment'] = df['day_of_week'].apply(get_week_segment)\n",
        "\n",
        "    def get_season_category(month_num):\n",
        "        # Example: Simple classification. Replace with your actual logic.\n",
        "        if month_num in [12, 1, 2]: return 'winter'\n",
        "        elif month_num in [3, 4, 5]: return 'spring'\n",
        "        elif month_num in [6, 7, 8]: return 'summer'\n",
        "        else: return 'autumn'\n",
        "    df['season_category'] = df['month_numeric'].apply(get_season_category)\n",
        "    df = df.drop(columns=['month_numeric']) # Drop temporary column if created\n",
        "\n",
        "    # Example: recently_contacted (based on pdays or previous)\n",
        "    # Assuming pdays == 999 means not previously contacted\n",
        "    df['recently_contacted'] = (df['pdays'] != 999).astype(int)\n",
        "\n",
        "    # Example: is_employed (based on job)\n",
        "    # Assuming 'unemployed' and 'student' are not employed. Adjust based on your definition.\n",
        "    df['is_employed'] = (~df['job'].isin(['unemployed', 'student'])).astype(int)\n",
        "\n",
        "    # --- END FEATURE ENGINEERING ---\n",
        "\n",
        "    # Now, transform the data with the loaded pipeline (which expects all these columns)\n",
        "    try:\n",
        "        X_clean = pipeline.transform(df)\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Error during pipeline transformation: {e}\"}), 500\n",
        "\n",
        "    # Make prediction\n",
        "    try:\n",
        "        pred = model.predict(X_clean)[0]\n",
        "        # For classification, also return probabilities for more insight\n",
        "        pred_proba = model.predict_proba(X_clean)[0]\n",
        "        prediction_no = pred_proba[0] # Probability of \"no\"\n",
        "        prediction_yes = pred_proba[1] # Probability of \"yes\"\n",
        "\n",
        "        return jsonify({\n",
        "            \"prediction\": int(pred),\n",
        "            \"prediction_proba_no\": float(prediction_no),\n",
        "            \"prediction_proba_yes\": float(prediction_yes)\n",
        "        })\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": f\"Error during prediction: {e}\"}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure debug=False for production environments\n",
        "    app.run(host=\"0.0.0.0\", port=5000, debug=False)"
      ]
    }
  ]
}